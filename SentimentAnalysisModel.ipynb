{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017584,
     "end_time": "2020-08-10T17:23:53.726945",
     "exception": false,
     "start_time": "2020-08-10T17:23:53.709361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sentiment Analysis on COVID19 Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-10T17:23:53.813446Z",
     "iopub.status.busy": "2020-08-10T17:23:53.812764Z",
     "iopub.status.idle": "2020-08-10T17:23:54.537689Z",
     "shell.execute_reply": "2020-08-10T17:23:54.536275Z"
    },
    "papermill": {
     "duration": 0.745526,
     "end_time": "2020-08-10T17:23:54.537846",
     "exception": false,
     "start_time": "2020-08-10T17:23:53.792320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"./covid19_tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03544,
     "end_time": "2020-08-10T17:24:38.007502",
     "exception": false,
     "start_time": "2020-08-10T17:24:37.972062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Exploring Tweet Data\n",
    "\n",
    "* Sentiment Analysis on Covid19 Tweets\n",
    "    * Exploring tweet data\n",
    "    * Encoding tweets\n",
    "    * Encoding sentiments\n",
    "    * Detecting outlier reviews\n",
    "    * Training, testing and validating\n",
    "    * Dataloaders and batching\n",
    "    * Sentiment network with PyTorch\n",
    "    * Instantiate the netork\n",
    "    * Calculating model's accuracy\n",
    "    * Testing model on a random covid19 tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:38.121557Z",
     "iopub.status.busy": "2020-08-10T17:24:38.120605Z",
     "iopub.status.idle": "2020-08-10T17:24:38.139349Z",
     "shell.execute_reply": "2020-08-10T17:24:38.140622Z"
    },
    "papermill": {
     "duration": 0.095601,
     "end_time": "2020-08-10T17:24:38.140852",
     "exception": false,
     "start_time": "2020-08-10T17:24:38.045251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_csv('/kaggle/input/twitterdata/finalSentimentdata2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:38.280922Z",
     "iopub.status.busy": "2020-08-10T17:24:38.280048Z",
     "iopub.status.idle": "2020-08-10T17:24:38.286871Z",
     "shell.execute_reply": "2020-08-10T17:24:38.287610Z"
    },
    "papermill": {
     "duration": 0.084868,
     "end_time": "2020-08-10T17:24:38.287802",
     "exception": false,
     "start_time": "2020-08-10T17:24:38.202934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3204</td>\n",
       "      <td>sad</td>\n",
       "      <td>agree the poor in india are treated badly thei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1431</td>\n",
       "      <td>joy</td>\n",
       "      <td>if only i could have spent the with this cutie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>654</td>\n",
       "      <td>joy</td>\n",
       "      <td>will nature conservation remain a priority in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2530</td>\n",
       "      <td>sad</td>\n",
       "      <td>coronavirus disappearing in italy show this to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2296</td>\n",
       "      <td>sad</td>\n",
       "      <td>uk records lowest daily virus death toll since...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 sentiment                                               text\n",
       "0        3204       sad  agree the poor in india are treated badly thei...\n",
       "1        1431       joy  if only i could have spent the with this cutie...\n",
       "2         654       joy  will nature conservation remain a priority in ...\n",
       "3        2530       sad  coronavirus disappearing in italy show this to...\n",
       "4        2296       sad  uk records lowest daily virus death toll since..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:38.409999Z",
     "iopub.status.busy": "2020-08-10T17:24:38.409035Z",
     "iopub.status.idle": "2020-08-10T17:24:38.416800Z",
     "shell.execute_reply": "2020-08-10T17:24:38.417514Z"
    },
    "papermill": {
     "duration": 0.071071,
     "end_time": "2020-08-10T17:24:38.417694",
     "exception": false,
     "start_time": "2020-08-10T17:24:38.346623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sentiment', 'text'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:38.507785Z",
     "iopub.status.busy": "2020-08-10T17:24:38.506948Z",
     "iopub.status.idle": "2020-08-10T17:24:38.510683Z",
     "shell.execute_reply": "2020-08-10T17:24:38.511189Z"
    },
    "papermill": {
     "duration": 0.049634,
     "end_time": "2020-08-10T17:24:38.511319",
     "exception": false,
     "start_time": "2020-08-10T17:24:38.461685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.nunique of 0         sad\n",
       "1         joy\n",
       "2         joy\n",
       "3         sad\n",
       "4         sad\n",
       "        ...  \n",
       "3085      sad\n",
       "3086    anger\n",
       "3087      joy\n",
       "3088      sad\n",
       "3089      sad\n",
       "Name: sentiment, Length: 3090, dtype: object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df['sentiment'].nunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:38.593229Z",
     "iopub.status.busy": "2020-08-10T17:24:38.592051Z",
     "iopub.status.idle": "2020-08-10T17:24:49.894045Z",
     "shell.execute_reply": "2020-08-10T17:24:49.894642Z"
    },
    "papermill": {
     "duration": 11.345753,
     "end_time": "2020-08-10T17:24:49.894807",
     "exception": false,
     "start_time": "2020-08-10T17:24:38.549054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentiment_df.loc[:, 'text'] = sentiment_df['text'].apply(punctuation_stopwords_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:50.043694Z",
     "iopub.status.busy": "2020-08-10T17:24:50.038644Z",
     "iopub.status.idle": "2020-08-10T17:24:50.380876Z",
     "shell.execute_reply": "2020-08-10T17:24:50.380289Z"
    },
    "papermill": {
     "duration": 0.423263,
     "end_time": "2020-08-10T17:24:50.381016",
     "exception": false,
     "start_time": "2020-08-10T17:24:49.957753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reviews_split = []\n",
    "for i, j in sentiment_df.iterrows():\n",
    "    reviews_split.append(j['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:50.472431Z",
     "iopub.status.busy": "2020-08-10T17:24:50.470482Z",
     "iopub.status.idle": "2020-08-10T17:24:50.475802Z",
     "shell.execute_reply": "2020-08-10T17:24:50.475290Z"
    },
    "papermill": {
     "duration": 0.056074,
     "end_time": "2020-08-10T17:24:50.475923",
     "exception": false,
     "start_time": "2020-08-10T17:24:50.419849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "for review in reviews_split:\n",
    "    for word in review:\n",
    "        words.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:50.555410Z",
     "iopub.status.busy": "2020-08-10T17:24:50.554641Z",
     "iopub.status.idle": "2020-08-10T17:24:50.558525Z",
     "shell.execute_reply": "2020-08-10T17:24:50.559002Z"
    },
    "papermill": {
     "duration": 0.045968,
     "end_time": "2020-08-10T17:24:50.559130",
     "exception": false,
     "start_time": "2020-08-10T17:24:50.513162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agree', 'poor', 'india', 'treated', 'badly', 'poors', 'seek', 'living', 'singapore', 'treated', 'like', 'citizens', 'given', 'free', 'medical', 'treatment', 'given', 'food', 'daily', 'sim']\n"
     ]
    }
   ],
   "source": [
    "print(words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03664,
     "end_time": "2020-08-10T17:24:50.633407",
     "exception": false,
     "start_time": "2020-08-10T17:24:50.596767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoding Tweets\n",
    "Create an array that contains integer encoded version of words in reviews. The word appearing the most should have least integer value. Example if the appeared the most in reviews, then assign 'the' : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:50.725479Z",
     "iopub.status.busy": "2020-08-10T17:24:50.724689Z",
     "iopub.status.idle": "2020-08-10T17:24:50.728235Z",
     "shell.execute_reply": "2020-08-10T17:24:50.728674Z"
    },
    "papermill": {
     "duration": 0.057689,
     "end_time": "2020-08-10T17:24:50.728807",
     "exception": false,
     "start_time": "2020-08-10T17:24:50.671118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(words)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word:ii for ii, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:50.822520Z",
     "iopub.status.busy": "2020-08-10T17:24:50.820588Z",
     "iopub.status.idle": "2020-08-10T17:24:50.823449Z",
     "shell.execute_reply": "2020-08-10T17:24:50.823986Z"
    },
    "papermill": {
     "duration": 0.055828,
     "end_time": "2020-08-10T17:24:50.824117",
     "exception": false,
     "start_time": "2020-08-10T17:24:50.768289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_reviews = []\n",
    "for review in reviews_split:\n",
    "    encoded_reviews.append([vocab_to_int[word] for word in review])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:50.906037Z",
     "iopub.status.busy": "2020-08-10T17:24:50.905302Z",
     "iopub.status.idle": "2020-08-10T17:24:50.909751Z",
     "shell.execute_reply": "2020-08-10T17:24:50.910214Z"
    },
    "papermill": {
     "duration": 0.047256,
     "end_time": "2020-08-10T17:24:50.910347",
     "exception": false,
     "start_time": "2020-08-10T17:24:50.863091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10662\n",
      "[[853, 186, 20, 1079, 1457, 4429, 2201, 407, 1240, 1079, 15, 218, 337, 167, 253, 462, 337, 122, 168, 4430, 4431, 140, 23, 264, 58, 765, 3, 5, 195, 1079, 2966, 274], [80, 1755, 4432, 2967, 4433, 86, 854, 1080, 2968, 4434, 4435, 7], [543, 4436, 946, 1458, 265, 2, 1241, 168, 2202], [1, 4437, 169, 266, 1459, 129, 1242, 47, 7], [304, 1756, 4438, 168, 8, 39, 219, 93, 355, 4, 21], [2203, 2204, 1, 1757, 1243, 2969, 1460, 1081, 1461, 4439, 98, 4440], [947, 37, 1758, 285, 948, 4441, 1462, 2205, 13, 3, 5, 4442, 285, 1244, 4443, 1463, 4444, 4445, 286, 4446, 15, 4447, 47, 228, 2970, 338, 40, 312, 1463, 179, 1759], [41, 377, 149, 1245, 4448, 34], [2206, 649, 180, 1760, 2207, 91, 650, 378, 463, 1246, 595, 1464, 2208, 2, 8, 2209, 651, 40, 379, 2210, 21, 228, 703, 1246, 1761, 408], [2206, 649, 180, 1760, 2207, 91, 650, 378, 463, 1246, 595, 1464, 2208, 2, 8, 2209, 651, 40, 379, 2210, 21, 228, 703, 1246, 2971]]\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab_to_int))\n",
    "print(encoded_reviews[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.037086,
     "end_time": "2020-08-10T17:24:50.986299",
     "exception": false,
     "start_time": "2020-08-10T17:24:50.949213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Encoding Sentiments\n",
    "\n",
    "For simplicity purposes, I am encoding positive sentiment such as joy as 1 and rest (anger, sad) as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:51.100361Z",
     "iopub.status.busy": "2020-08-10T17:24:51.090206Z",
     "iopub.status.idle": "2020-08-10T17:24:51.394459Z",
     "shell.execute_reply": "2020-08-10T17:24:51.394953Z"
    },
    "papermill": {
     "duration": 0.370607,
     "end_time": "2020-08-10T17:24:51.395114",
     "exception": false,
     "start_time": "2020-08-10T17:24:51.024507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels_to_int = []\n",
    "for i, j in sentiment_df.iterrows():\n",
    "    if j['sentiment']=='joy':\n",
    "        labels_to_int.append(1)\n",
    "    else:\n",
    "        labels_to_int.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040247,
     "end_time": "2020-08-10T17:24:51.475113",
     "exception": false,
     "start_time": "2020-08-10T17:24:51.434866",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Detecting any outlier reviews\n",
    "\n",
    "This step involves -<br>\n",
    "1. Getting rid of extremely long/short reviews\n",
    "2. Padding/truncating reaining data to maintain constant review length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:51.556784Z",
     "iopub.status.busy": "2020-08-10T17:24:51.556168Z",
     "iopub.status.idle": "2020-08-10T17:24:51.561633Z",
     "shell.execute_reply": "2020-08-10T17:24:51.561084Z"
    },
    "papermill": {
     "duration": 0.048781,
     "end_time": "2020-08-10T17:24:51.561733",
     "exception": false,
     "start_time": "2020-08-10T17:24:51.512952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "reviews_len = Counter([len(x) for x in encoded_reviews])\n",
    "print(max(reviews_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:51.647406Z",
     "iopub.status.busy": "2020-08-10T17:24:51.646586Z",
     "iopub.status.idle": "2020-08-10T17:24:51.652176Z",
     "shell.execute_reply": "2020-08-10T17:24:51.652687Z"
    },
    "papermill": {
     "duration": 0.051428,
     "end_time": "2020-08-10T17:24:51.652889",
     "exception": false,
     "start_time": "2020-08-10T17:24:51.601461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3090\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:51.741141Z",
     "iopub.status.busy": "2020-08-10T17:24:51.739202Z",
     "iopub.status.idle": "2020-08-10T17:24:51.741811Z",
     "shell.execute_reply": "2020-08-10T17:24:51.742292Z"
    },
    "papermill": {
     "duration": 0.049949,
     "end_time": "2020-08-10T17:24:51.742431",
     "exception": false,
     "start_time": "2020-08-10T17:24:51.692482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_zero_idx = [ii for ii, review in enumerate(encoded_reviews) if len(encoded_reviews)!=0]\n",
    "encoded_reviews = [encoded_reviews[ii] for ii in non_zero_idx]\n",
    "encoded_labels = np.array([labels_to_int[ii] for ii in non_zero_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:51.829298Z",
     "iopub.status.busy": "2020-08-10T17:24:51.828494Z",
     "iopub.status.idle": "2020-08-10T17:24:51.833600Z",
     "shell.execute_reply": "2020-08-10T17:24:51.834381Z"
    },
    "papermill": {
     "duration": 0.052055,
     "end_time": "2020-08-10T17:24:51.834564",
     "exception": false,
     "start_time": "2020-08-10T17:24:51.782509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3090\n",
      "3090\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded_reviews))\n",
    "print(len(encoded_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:51.923947Z",
     "iopub.status.busy": "2020-08-10T17:24:51.922093Z",
     "iopub.status.idle": "2020-08-10T17:24:51.924600Z",
     "shell.execute_reply": "2020-08-10T17:24:51.925068Z"
    },
    "papermill": {
     "duration": 0.049669,
     "end_time": "2020-08-10T17:24:51.925200",
     "exception": false,
     "start_time": "2020-08-10T17:24:51.875531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_features(reviews_int, seq_length):\n",
    "    features = np.zeros((len(reviews_int), seq_length), dtype=int)\n",
    "    for i, row in enumerate(reviews_int):\n",
    "        if len(row)!=0:\n",
    "            features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:52.015570Z",
     "iopub.status.busy": "2020-08-10T17:24:52.012189Z",
     "iopub.status.idle": "2020-08-10T17:24:52.042035Z",
     "shell.execute_reply": "2020-08-10T17:24:52.041405Z"
    },
    "papermill": {
     "duration": 0.076024,
     "end_time": "2020-08-10T17:24:52.042163",
     "exception": false,
     "start_time": "2020-08-10T17:24:51.966139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0  853  186   20 1079 1457 4429 2201  407 1240 1079\n",
      "    15  218  337  167  253  462  337  122  168 4430 4431  140   23  264\n",
      "    58  765    3    5  195 1079 2966  274]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0   80 1755 4432 2967\n",
      "  4433   86  854 1080 2968 4434 4435    7]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 50\n",
    "padded_features= pad_features(encoded_reviews, seq_length)\n",
    "print(padded_features[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039512,
     "end_time": "2020-08-10T17:24:52.123994",
     "exception": false,
     "start_time": "2020-08-10T17:24:52.084482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training, Testing and Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:52.213181Z",
     "iopub.status.busy": "2020-08-10T17:24:52.212141Z",
     "iopub.status.idle": "2020-08-10T17:24:52.215230Z",
     "shell.execute_reply": "2020-08-10T17:24:52.214707Z"
    },
    "papermill": {
     "duration": 0.051353,
     "end_time": "2020-08-10T17:24:52.215339",
     "exception": false,
     "start_time": "2020-08-10T17:24:52.163986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_frac = 0.8\n",
    "split_idx = int(len(padded_features)*split_frac)\n",
    "\n",
    "training_x, remaining_x = padded_features[:split_idx], padded_features[split_idx:]\n",
    "training_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
    "\n",
    "test_idx = int(len(remaining_x)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057143,
     "end_time": "2020-08-10T17:24:52.312294",
     "exception": false,
     "start_time": "2020-08-10T17:24:52.255151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataloaders and Batching\n",
    "\n",
    "A neat way to create data-loaders and batch our training, validation and test Tensor datasets is as follows -<br>\n",
    "```python\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "```\n",
    "This is an alternative to creating a generator function for batching our data into full batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:52.462787Z",
     "iopub.status.busy": "2020-08-10T17:24:52.461701Z",
     "iopub.status.idle": "2020-08-10T17:24:54.030745Z",
     "shell.execute_reply": "2020-08-10T17:24:54.029067Z"
    },
    "papermill": {
     "duration": 1.646106,
     "end_time": "2020-08-10T17:24:54.030927",
     "exception": false,
     "start_time": "2020-08-10T17:24:52.384821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:54.128909Z",
     "iopub.status.busy": "2020-08-10T17:24:54.127010Z",
     "iopub.status.idle": "2020-08-10T17:24:54.129572Z",
     "shell.execute_reply": "2020-08-10T17:24:54.130101Z"
    },
    "papermill": {
     "duration": 0.057114,
     "end_time": "2020-08-10T17:24:54.130248",
     "exception": false,
     "start_time": "2020-08-10T17:24:54.073134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.from_numpy creates a tensor data from n-d array\n",
    "train_data = TensorDataset(torch.from_numpy(training_x), torch.from_numpy(training_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:54.215428Z",
     "iopub.status.busy": "2020-08-10T17:24:54.214723Z",
     "iopub.status.idle": "2020-08-10T17:24:54.218765Z",
     "shell.execute_reply": "2020-08-10T17:24:54.219619Z"
    },
    "papermill": {
     "duration": 0.049966,
     "end_time": "2020-08-10T17:24:54.219891",
     "exception": false,
     "start_time": "2020-08-10T17:24:54.169925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_available = torch.cuda.is_available\n",
    "\n",
    "if gpu_available:\n",
    "    print('Training on GPU')\n",
    "else:\n",
    "    print('GPU not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.04245,
     "end_time": "2020-08-10T17:24:54.305757",
     "exception": false,
     "start_time": "2020-08-10T17:24:54.263307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sentiment Network with PyTorch\n",
    "Below are the various layers of our RNN that would perform sentiment analysis -<br>\n",
    "1. An *embedding layer* that converts our word tokens (integers) into embeddings of a specific size.\n",
    "2. A *LSTM layer* defined by a hidden_state size and number of layers\n",
    "3. A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n",
    "4. A sigmoid activation layer which turns all outputs into a value 0-1; return only the last sigmoid output as the output of this network.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:54.418336Z",
     "iopub.status.busy": "2020-08-10T17:24:54.417350Z",
     "iopub.status.idle": "2020-08-10T17:24:54.420412Z",
     "shell.execute_reply": "2020-08-10T17:24:54.419751Z"
    },
    "papermill": {
     "duration": 0.061351,
     "end_time": "2020-08-10T17:24:54.420525",
     "exception": false,
     "start_time": "2020-08-10T17:24:54.359174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CovidTweetSentimentAnalysis(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.2):\n",
    "        super(CovidTweetSentimentAnalysis, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # x : batch_size * seq_length * features\n",
    "        batch_size = x.size(0)\n",
    "        x = x.long()\n",
    "        embeds = self.embedding_layer(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1]\n",
    "        \n",
    "        return sig_out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # initialize weights for lstm layer\n",
    "        weights = next(self.parameters()).data\n",
    "        \n",
    "        if gpu_available:\n",
    "            hidden = (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                     weights.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weights.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                     weights.new(self.n_layers, batch_size, self.hidden_dim).zero())\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040089,
     "end_time": "2020-08-10T17:24:54.502660",
     "exception": false,
     "start_time": "2020-08-10T17:24:54.462571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Instantiate the network\n",
    "Here, I will define the model hyper-parameters -<br>\n",
    "\n",
    "1. `vocab_size` : Size of our vocabulary or the range of values for our input, word tokens.\n",
    "2. `output_size` : Size of our desired output; the number of class scores we want to output (pos/neg).\n",
    "3. `embedding_dim` : Number of columns in the embedding lookup table; size of our embeddings.\n",
    "4. `hidden_dim` : Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
    "5. `n_layers`: Number of LSTM layers in the network. Typically between 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:54.589663Z",
     "iopub.status.busy": "2020-08-10T17:24:54.588758Z",
     "iopub.status.idle": "2020-08-10T17:24:54.592105Z",
     "shell.execute_reply": "2020-08-10T17:24:54.591528Z"
    },
    "papermill": {
     "duration": 0.047992,
     "end_time": "2020-08-10T17:24:54.592222",
     "exception": false,
     "start_time": "2020-08-10T17:24:54.544230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1 # either happy or sad\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:54.689247Z",
     "iopub.status.busy": "2020-08-10T17:24:54.688211Z",
     "iopub.status.idle": "2020-08-10T17:24:54.796444Z",
     "shell.execute_reply": "2020-08-10T17:24:54.797577Z"
    },
    "papermill": {
     "duration": 0.16719,
     "end_time": "2020-08-10T17:24:54.797781",
     "exception": false,
     "start_time": "2020-08-10T17:24:54.630591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CovidTweetSentimentAnalysis(\n",
      "  (embedding_layer): Embedding(10663, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = CovidTweetSentimentAnalysis(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:54.934097Z",
     "iopub.status.busy": "2020-08-10T17:24:54.933083Z",
     "iopub.status.idle": "2020-08-10T17:24:54.937310Z",
     "shell.execute_reply": "2020-08-10T17:24:54.938025Z"
    },
    "papermill": {
     "duration": 0.075585,
     "end_time": "2020-08-10T17:24:54.938218",
     "exception": false,
     "start_time": "2020-08-10T17:24:54.862633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:24:55.697805Z",
     "iopub.status.busy": "2020-08-10T17:24:55.692990Z",
     "iopub.status.idle": "2020-08-10T17:26:15.028961Z",
     "shell.execute_reply": "2020-08-10T17:26:15.028314Z"
    },
    "papermill": {
     "duration": 80.025071,
     "end_time": "2020-08-10T17:26:15.029109",
     "exception": false,
     "start_time": "2020-08-10T17:24:55.004038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.136036... Val Loss: 0.139115\n",
      "Epoch: 1/4... Step: 200... Loss: 0.057192... Val Loss: 0.103990\n",
      "Epoch: 1/4... Step: 300... Loss: 0.192796... Val Loss: 0.082102\n",
      "Epoch: 1/4... Step: 400... Loss: 0.068804... Val Loss: 0.805758\n",
      "Epoch: 1/4... Step: 500... Loss: 0.662398... Val Loss: 0.666439\n",
      "Epoch: 1/4... Step: 600... Loss: 0.039760... Val Loss: 0.278505\n",
      "Epoch: 1/4... Step: 700... Loss: 1.115070... Val Loss: 0.351145\n",
      "Epoch: 1/4... Step: 800... Loss: 0.792689... Val Loss: 0.476311\n",
      "Epoch: 1/4... Step: 900... Loss: 0.744873... Val Loss: 0.747945\n",
      "Epoch: 1/4... Step: 1000... Loss: 0.023593... Val Loss: 0.638791\n",
      "Epoch: 1/4... Step: 1100... Loss: 0.093999... Val Loss: 0.229394\n",
      "Epoch: 1/4... Step: 1200... Loss: 1.009879... Val Loss: 0.599059\n",
      "Epoch: 1/4... Step: 1300... Loss: 0.033126... Val Loss: 0.420905\n",
      "Epoch: 1/4... Step: 1400... Loss: 0.052237... Val Loss: 0.542419\n",
      "Epoch: 1/4... Step: 1500... Loss: 1.461284... Val Loss: 0.670432\n",
      "Epoch: 1/4... Step: 1600... Loss: 0.814882... Val Loss: 0.177111\n",
      "Epoch: 1/4... Step: 1700... Loss: 2.494245... Val Loss: 0.062890\n",
      "Epoch: 1/4... Step: 1800... Loss: 0.047719... Val Loss: 0.194314\n",
      "Epoch: 1/4... Step: 1900... Loss: 0.112892... Val Loss: 0.090223\n",
      "Epoch: 1/4... Step: 2000... Loss: 0.275264... Val Loss: 0.305600\n",
      "Epoch: 1/4... Step: 2100... Loss: 0.042246... Val Loss: 0.549527\n",
      "Epoch: 1/4... Step: 2200... Loss: 0.605744... Val Loss: 0.310995\n",
      "Epoch: 1/4... Step: 2300... Loss: 0.535095... Val Loss: 0.336425\n",
      "Epoch: 1/4... Step: 2400... Loss: 0.019273... Val Loss: 0.159368\n",
      "Epoch: 2/4... Step: 2500... Loss: 0.590046... Val Loss: 0.249203\n",
      "Epoch: 2/4... Step: 2600... Loss: 0.017309... Val Loss: 0.303547\n",
      "Epoch: 2/4... Step: 2700... Loss: 0.120395... Val Loss: 0.051117\n",
      "Epoch: 2/4... Step: 2800... Loss: 0.051600... Val Loss: 0.044428\n",
      "Epoch: 2/4... Step: 2900... Loss: 0.009870... Val Loss: 0.027375\n",
      "Epoch: 2/4... Step: 3000... Loss: 0.003255... Val Loss: 0.058751\n",
      "Epoch: 2/4... Step: 3100... Loss: 0.035396... Val Loss: 0.056241\n",
      "Epoch: 2/4... Step: 3200... Loss: 0.012480... Val Loss: 0.066974\n",
      "Epoch: 2/4... Step: 3300... Loss: 0.540439... Val Loss: 0.043544\n",
      "Epoch: 2/4... Step: 3400... Loss: 1.935728... Val Loss: 0.086820\n",
      "Epoch: 2/4... Step: 3500... Loss: 0.183907... Val Loss: 0.036250\n",
      "Epoch: 2/4... Step: 3600... Loss: 1.556695... Val Loss: 0.067435\n",
      "Epoch: 2/4... Step: 3700... Loss: 0.011356... Val Loss: 0.026317\n",
      "Epoch: 2/4... Step: 3800... Loss: 0.010023... Val Loss: 0.099391\n",
      "Epoch: 2/4... Step: 3900... Loss: 0.003534... Val Loss: 0.055300\n",
      "Epoch: 2/4... Step: 4000... Loss: 0.153534... Val Loss: 0.017880\n",
      "Epoch: 2/4... Step: 4100... Loss: 2.927799... Val Loss: 0.204677\n",
      "Epoch: 2/4... Step: 4200... Loss: 0.009972... Val Loss: 0.246071\n",
      "Epoch: 2/4... Step: 4300... Loss: 0.792031... Val Loss: 0.006092\n",
      "Epoch: 2/4... Step: 4400... Loss: 0.093652... Val Loss: 0.142858\n",
      "Epoch: 2/4... Step: 4500... Loss: 0.046579... Val Loss: 0.024530\n",
      "Epoch: 2/4... Step: 4600... Loss: 3.282031... Val Loss: 0.024903\n",
      "Epoch: 2/4... Step: 4700... Loss: 0.001956... Val Loss: 0.013717\n",
      "Epoch: 2/4... Step: 4800... Loss: 0.024367... Val Loss: 0.010086\n",
      "Epoch: 2/4... Step: 4900... Loss: 0.045069... Val Loss: 0.009611\n",
      "Epoch: 3/4... Step: 5000... Loss: 0.000247... Val Loss: 0.003183\n",
      "Epoch: 3/4... Step: 5100... Loss: 0.000274... Val Loss: 0.001842\n",
      "Epoch: 3/4... Step: 5200... Loss: 0.000242... Val Loss: 0.001447\n",
      "Epoch: 3/4... Step: 5300... Loss: 0.000309... Val Loss: 0.003289\n",
      "Epoch: 3/4... Step: 5400... Loss: 0.000497... Val Loss: 0.005436\n",
      "Epoch: 3/4... Step: 5500... Loss: 0.158719... Val Loss: 0.003422\n",
      "Epoch: 3/4... Step: 5600... Loss: 0.006418... Val Loss: 0.002375\n",
      "Epoch: 3/4... Step: 5700... Loss: 0.000654... Val Loss: 0.002442\n",
      "Epoch: 3/4... Step: 5800... Loss: 0.000403... Val Loss: 0.000681\n",
      "Epoch: 3/4... Step: 5900... Loss: 0.000695... Val Loss: 0.014224\n",
      "Epoch: 3/4... Step: 6000... Loss: 0.013184... Val Loss: 0.002457\n",
      "Epoch: 3/4... Step: 6100... Loss: 0.001609... Val Loss: 0.004525\n",
      "Epoch: 3/4... Step: 6200... Loss: 0.000490... Val Loss: 0.000552\n",
      "Epoch: 3/4... Step: 6300... Loss: 0.003102... Val Loss: 0.000449\n",
      "Epoch: 3/4... Step: 6400... Loss: 0.000427... Val Loss: 0.000192\n",
      "Epoch: 3/4... Step: 6500... Loss: 0.005188... Val Loss: 0.000178\n",
      "Epoch: 3/4... Step: 6600... Loss: 0.000894... Val Loss: 0.001854\n",
      "Epoch: 3/4... Step: 6700... Loss: 0.003325... Val Loss: 0.001681\n",
      "Epoch: 3/4... Step: 6800... Loss: 0.001351... Val Loss: 0.000515\n",
      "Epoch: 3/4... Step: 6900... Loss: 0.000475... Val Loss: 0.001130\n",
      "Epoch: 3/4... Step: 7000... Loss: 0.000832... Val Loss: 0.000541\n",
      "Epoch: 3/4... Step: 7100... Loss: 0.000041... Val Loss: 0.000378\n",
      "Epoch: 3/4... Step: 7200... Loss: 0.001911... Val Loss: 0.000361\n",
      "Epoch: 3/4... Step: 7300... Loss: 0.000315... Val Loss: 0.000167\n",
      "Epoch: 3/4... Step: 7400... Loss: 0.012290... Val Loss: 0.000133\n",
      "Epoch: 4/4... Step: 7500... Loss: 0.000561... Val Loss: 0.000159\n",
      "Epoch: 4/4... Step: 7600... Loss: 0.000014... Val Loss: 0.000100\n",
      "Epoch: 4/4... Step: 7700... Loss: 0.000223... Val Loss: 0.000072\n",
      "Epoch: 4/4... Step: 7800... Loss: 0.000021... Val Loss: 0.000061\n",
      "Epoch: 4/4... Step: 7900... Loss: 0.000024... Val Loss: 0.000079\n",
      "Epoch: 4/4... Step: 8000... Loss: 0.000029... Val Loss: 0.000016\n",
      "Epoch: 4/4... Step: 8100... Loss: 0.000008... Val Loss: 0.000015\n",
      "Epoch: 4/4... Step: 8200... Loss: 0.000430... Val Loss: 0.000016\n",
      "Epoch: 4/4... Step: 8300... Loss: 0.000142... Val Loss: 0.000018\n",
      "Epoch: 4/4... Step: 8400... Loss: 0.000012... Val Loss: 0.000019\n",
      "Epoch: 4/4... Step: 8500... Loss: 0.000033... Val Loss: 0.000021\n",
      "Epoch: 4/4... Step: 8600... Loss: 0.000036... Val Loss: 0.000019\n",
      "Epoch: 4/4... Step: 8700... Loss: 0.000021... Val Loss: 0.000018\n",
      "Epoch: 4/4... Step: 8800... Loss: 0.000043... Val Loss: 0.000032\n",
      "Epoch: 4/4... Step: 8900... Loss: 0.000011... Val Loss: 0.000013\n",
      "Epoch: 4/4... Step: 9000... Loss: 0.000058... Val Loss: 0.000012\n",
      "Epoch: 4/4... Step: 9100... Loss: 0.000007... Val Loss: 0.000012\n",
      "Epoch: 4/4... Step: 9200... Loss: 0.000034... Val Loss: 0.000012\n",
      "Epoch: 4/4... Step: 9300... Loss: 0.000056... Val Loss: 0.000424\n",
      "Epoch: 4/4... Step: 9400... Loss: 0.000012... Val Loss: 0.000130\n",
      "Epoch: 4/4... Step: 9500... Loss: 0.000020... Val Loss: 0.000032\n",
      "Epoch: 4/4... Step: 9600... Loss: 0.000144... Val Loss: 0.000015\n",
      "Epoch: 4/4... Step: 9700... Loss: 0.000656... Val Loss: 0.000007\n",
      "Epoch: 4/4... Step: 9800... Loss: 0.000024... Val Loss: 0.000006\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "count = 0\n",
    "print_every = 100\n",
    "clip = 5 \n",
    "if gpu_available:\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "for e in range(epochs):\n",
    "    # initialize lstm's hidden layer \n",
    "    h = net.init_hidden(batch_size)\n",
    "    for inputs, labels in train_loader:\n",
    "        count += 1\n",
    "        if gpu_available:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        h = tuple([each.data for each in h])\n",
    "        \n",
    "        # training process\n",
    "        net.zero_grad()\n",
    "        outputs, h = net(inputs, h)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print average training losses\n",
    "        if count % print_every == 0:\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "                if gpu_available:\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            outputs, val_h = net(inputs, val_h)\n",
    "            val_loss = criterion(outputs.squeeze(), labels.float())\n",
    "            val_losses.append(val_loss.item())\n",
    "        \n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(count),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046029,
     "end_time": "2020-08-10T17:26:15.124390",
     "exception": false,
     "start_time": "2020-08-10T17:26:15.078361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Calculating model's accuracy\n",
    "\n",
    "The `CovidTweetSentimentAnalysis` model achieved accuracy of 85.4 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:26:15.248279Z",
     "iopub.status.busy": "2020-08-10T17:26:15.247230Z",
     "iopub.status.idle": "2020-08-10T17:26:15.903460Z",
     "shell.execute_reply": "2020-08-10T17:26:15.904471Z"
    },
    "papermill": {
     "duration": 0.726371,
     "end_time": "2020-08-10T17:26:15.904670",
     "exception": false,
     "start_time": "2020-08-10T17:26:15.178299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.594\n",
      "Test accuracy: 0.890\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "num_correct = 0\n",
    "\n",
    "h = net.init_hidden(batch_size)\n",
    "net.eval()\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    h = tuple([each.data for each in h])\n",
    "    if gpu_available:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    outputs, h = net(inputs, h)\n",
    "    test_loss = criterion(outputs.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    pred = torch.round(outputs.squeeze())\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not gpu_available else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "# printing average statistics\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "    \n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.045005,
     "end_time": "2020-08-10T17:26:15.999142",
     "exception": false,
     "start_time": "2020-08-10T17:26:15.954137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing model on random tweet\n",
    "\n",
    "Since for performing sentiment analysis on covid 19 tweets, I on-boarded a completely different dataset in this notebook. Now that the our model is trained,we can use this model to perform sentiment analysis on tweets related to covid19 on this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:26:16.096605Z",
     "iopub.status.busy": "2020-08-10T17:26:16.095713Z",
     "iopub.status.idle": "2020-08-10T17:26:16.099839Z",
     "shell.execute_reply": "2020-08-10T17:26:16.099337Z"
    },
    "papermill": {
     "duration": 0.056411,
     "end_time": "2020-08-10T17:26:16.099965",
     "exception": false,
     "start_time": "2020-08-10T17:26:16.043554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "def tokenize_covid_tweet(tweet):\n",
    "    test_ints = []\n",
    "    test_ints.append([vocab_to_int[word] for word in tweet])\n",
    "    return test_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:26:16.201434Z",
     "iopub.status.busy": "2020-08-10T17:26:16.200573Z",
     "iopub.status.idle": "2020-08-10T17:26:16.204634Z",
     "shell.execute_reply": "2020-08-10T17:26:16.204086Z"
    },
    "papermill": {
     "duration": 0.058914,
     "end_time": "2020-08-10T17:26:16.204791",
     "exception": false,
     "start_time": "2020-08-10T17:26:16.145877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_covid_sentiment(net, test_tweet, seq_length=50):\n",
    "    print('Original Sentence :')\n",
    "    print(test_tweet)\n",
    "    \n",
    "    print('\\nAfter removing punctuations and stop-words :')\n",
    "    test_tweet = punctuation_stopwords_removal(test_tweet)\n",
    "    print(test_tweet)\n",
    "    \n",
    "    print('\\nAfter converting pre-processed tweet to tokens :')\n",
    "    tokenized_tweet = tokenize_covid_tweet(test_tweet)\n",
    "    print(tokenized_tweet)\n",
    "    \n",
    "    print('\\nAfter padding the tokens into fixed sequence lengths :')\n",
    "    padded_tweet = pad_features(tokenized_tweet, 50)\n",
    "    print(padded_tweet)\n",
    "    \n",
    "    feature_tensor = torch.from_numpy(padded_tweet)\n",
    "    batch_size = feature_tensor.size(0)\n",
    "    \n",
    "    if gpu_available:\n",
    "        feature_tensor = feature_tensor.cuda()\n",
    "    \n",
    "    h = net.init_hidden(batch_size)\n",
    "    output, h = net(feature_tensor, h)\n",
    "    \n",
    "    predicted_sentiment = torch.round(output.squeeze())\n",
    "    print('\\n==========Predicted Sentiment==========\\n')\n",
    "    if predicted_sentiment == 1:\n",
    "        print('Happy')\n",
    "    else:\n",
    "        print('Sad')\n",
    "    print('\\n==========Predicted Sentiment==========\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:26:16.305331Z",
     "iopub.status.busy": "2020-08-10T17:26:16.304413Z",
     "iopub.status.idle": "2020-08-10T17:26:16.322926Z",
     "shell.execute_reply": "2020-08-10T17:26:16.319058Z"
    },
    "papermill": {
     "duration": 0.070532,
     "end_time": "2020-08-10T17:26:16.323057",
     "exception": false,
     "start_time": "2020-08-10T17:26:16.252525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence :\n",
      "It is very sad to see the corona pandemic increasing at such an alarming rate\n",
      "\n",
      "After removing punctuations and stop-words :\n",
      "['sad', 'see', 'corona', 'pandemic', 'increasing', 'alarming', 'rate']\n",
      "\n",
      "After converting pre-processed tweet to tokens :\n",
      "[[328, 63, 2, 28, 1964, 6137, 267]]\n",
      "\n",
      "After padding the tokens into fixed sequence lengths :\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0  328   63    2   28 1964 6137  267]]\n",
      "\n",
      "==========Predicted Sentiment==========\n",
      "\n",
      "Sad\n",
      "\n",
      "==========Predicted Sentiment==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sad_tweet = 'It is very sad to see the corona pandemic increasing at such an alarming rate'\n",
    "predict_covid_sentiment(net, test_sad_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T17:26:16.419996Z",
     "iopub.status.busy": "2020-08-10T17:26:16.419348Z",
     "iopub.status.idle": "2020-08-10T17:26:16.435905Z",
     "shell.execute_reply": "2020-08-10T17:26:16.435354Z"
    },
    "papermill": {
     "duration": 0.066346,
     "end_time": "2020-08-10T17:26:16.436020",
     "exception": false,
     "start_time": "2020-08-10T17:26:16.369674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence :\n",
      "It is amazing to see that New Zealand reaches 100 days without Covid transmission!\n",
      "\n",
      "After removing punctuations and stop-words :\n",
      "['amazing', 'see', 'new', 'zealand', 'reaches', '100', 'days', 'without', 'covid', 'transmission']\n",
      "\n",
      "After converting pre-processed tweet to tokens :\n",
      "[[642, 63, 30, 9453, 8081, 225, 35, 125, 3, 1326]]\n",
      "\n",
      "After padding the tokens into fixed sequence lengths :\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0  642   63\n",
      "    30 9453 8081  225   35  125    3 1326]]\n",
      "\n",
      "==========Predicted Sentiment==========\n",
      "\n",
      "Happy\n",
      "\n",
      "==========Predicted Sentiment==========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_happy_tweet = 'It is amazing to see that New Zealand reaches 100 days without Covid transmission!'\n",
    "predict_covid_sentiment(net, test_happy_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.043072,
     "end_time": "2020-08-10T17:26:16.525210",
     "exception": false,
     "start_time": "2020-08-10T17:26:16.482138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "papermill": {
   "duration": 148.173584,
   "end_time": "2020-08-10T17:26:17.084286",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-10T17:23:48.910702",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
